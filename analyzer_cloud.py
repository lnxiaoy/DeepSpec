import os
import json
import sqlite3
import urllib3
import requests
import time
import google.generativeai as genai
from docx import Document
from concurrent.futures import ThreadPoolExecutor, as_completed
from colorama import init, Fore
from google.api_core import retry

init(autoreset=True)
# ==========================================
# ğŸ›‘ æ ¸å¿ƒä¿®å¤åŒºï¼šå…¨å±€ç¦ç”¨ SSL éªŒè¯
# ==========================================
# 1. ç¦ç”¨è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# 2. æš´åŠ›æ‰“è¡¥ä¸ï¼šå¼ºåˆ¶æ‰€æœ‰ requests è¯·æ±‚éƒ½ä¸éªŒè¯è¯ä¹¦
# è¿™æ˜¯è§£å†³ SSLCertVerificationError çš„ç»ˆææ–¹æ¡ˆ
old_merge_environment_settings = requests.Session.merge_environment_settings

def merge_environment_settings(self, url, proxies, stream, verify, cert):
    # æ— è®ºåŸæ¥è¦æ±‚ä»€ä¹ˆï¼Œè¿™é‡Œå¼ºåˆ¶æŠŠ verify è®¾ä¸º False
    return old_merge_environment_settings(self, url, proxies, stream, False, cert)

requests.Session.merge_environment_settings = merge_environment_settings
# ==========================================


# --- é…ç½®åŒºåŸŸ ---
# æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ Google AI Studio API Key
API_KEY = ""

# ä½¿ç”¨ Flash æ¨¡å‹ï¼Œé€Ÿåº¦æœ€å¿«ï¼Œä¸”å…è´¹é¢åº¦é«˜
MODEL_NAME = "gemini-2.5-flash" 

DOC_FOLDER = "E:/000_3GPP_Download/tdocs/RAN1_123" # æŒ‡å‘ä½ ä¸‹è½½å¥½çš„æ–‡ä»¶å¤¹
DB_NAME = "ran1_knowledge_cloud.db" # æ–°æ•°æ®åº“å
MAX_WORKERS = 1 # Google å…è´¹å±‚çº§é™åˆ¶å¹¶å‘ï¼Œå»ºè®® 2-5 ä¹‹é—´

# é…ç½® API
genai.configure(api_key=API_KEY, transport="rest")

# --- æ•°æ®åº“åˆå§‹åŒ– (ä¸€å¯¹å¤šç»“æ„) ---
def init_db():
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    # æ³¨æ„ï¼šè¿™é‡Œçš„ id æ˜¯è‡ªå¢ä¸»é”®ï¼Œfilename ä¸å†å”¯ä¸€
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS document_insights (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            filename TEXT,
            vendor TEXT,
            topic TEXT,             -- æ–°å¢ï¼šå…·ä½“çš„è®¨è®ºè¯é¢˜
            stance TEXT,
            key_argument TEXT,
            proposed_parameter TEXT,
            evidence_quote TEXT,
            is_verified BOOLEAN,
            analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    return conn

# --- è¯»å– Docx ---
def read_docx(file_path):
    try:
        doc = Document(file_path)
        full_text = [p.text for p in doc.paragraphs if len(p.text) > 10]
        # Gemini 1.5 Flash ä¸Šä¸‹æ–‡å¾ˆå¤§ï¼Œå¯ä»¥ç›´æ¥ä¸¢è¿›å» 3-5ä¸‡å­—æ²¡é—®é¢˜
        # è¿™é‡Œé™åˆ¶ä¸€ä¸‹åªæ˜¯ä¸ºäº†èŠ‚çœæµé‡ï¼Œ30000å­—ç¬¦é€šå¸¸å¤Ÿäº†
        return "\n".join(full_text)[:30000]
    except Exception:
        return None

# --- äº‘ç«¯åˆ†ææ ¸å¿ƒå‡½æ•° ---
@retry.Retry() # è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼Œåº”å¯¹ç½‘ç»œæ³¢åŠ¨
def analyze_with_gemini(text, filename):
    print(f"{Fore.CYAN}[{filename}] æ­£åœ¨è¿æ¥ Google API...", end="\r") # å¢åŠ è°ƒè¯•æ‰“å°
    
    # --- æ ¸å¿ƒä¿®æ”¹ 2: å¼ºåˆ¶ä½¿ç”¨ REST åè®® ---
    # è¿™èƒ½è§£å†³ 99% çš„â€œå¡ä½â€é—®é¢˜
    model = genai.GenerativeModel(MODEL_NAME)
    
    # å¼ºåˆ¶è®©æ¨¡å‹è¾“å‡º JSON æ•°ç»„
    prompt = f"""
    You are a 3GPP RAN1 Standard Expert. 
    Analyze the following TDoc text from file '{filename}'.
    
    Task: Identify ALL distinct technical proposals/observations in this document.
    
    Output Format: return a standard JSON LIST (Array) of objects.
    
    JSON Schema for each object:
    {{
        "topic": "Specific technical topic (e.g. 'DMRS density', 'CSI overhead', 'AI Model generalization')",
        "vendor": "Company Name",
        "stance": "Support / Object / Neutral",
        "key_argument": "Technical reasoning (max 20 words)",
        "proposed_parameter": "Any specific values (e.g. '4 ports', '3dB') or null",
        "evidence_quote": "Exact sentence from text supporting this point"
    }}

    Text content:
    {text}
    """
    
    try:
        # è®¾ç½®å“åº”ç±»å‹ä¸º JSONï¼ŒGemini ä¸“å±åŠŸèƒ½
        response = model.generate_content(
            prompt,
            generation_config={"response_mime_type": "application/json"}
        )
        print(f"{Fore.BLUE}[{filename}] API å“åº”æˆåŠŸï¼      ") # ç©ºæ ¼æ˜¯ä¸ºäº†è¦†ç›–ä¹‹å‰çš„æ‰“å°
        return response.text
    except Exception as e:
        print(f"{Fore.RED}API Error ({filename}): {e}")
        return None

# --- æ ¡éªŒé€»è¾‘ ---
def verify_and_parse(original_text, json_str):
    valid_records = []
    try:
        data_list = json.loads(json_str)
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ¨¡å‹åªè¿”å›äº†ä¸€ä¸ªå¯¹è±¡è€Œä¸æ˜¯æ•°ç»„ï¼ŒæŠŠå®ƒåŒ…æˆæ•°ç»„
        if isinstance(data_list, dict):
            data_list = [data_list]
            
        for item in data_list:
            quote = item.get('evidence_quote', '')
            if quote:
                # ç®€åŒ–æ ¡éªŒï¼šå»é™¤ç©ºæ ¼åæŸ¥æ‰¾
                clean_quote = quote.replace(" ", "").strip()[:50] # åªåŒ¹é…å‰50ä¸ªå­—ç¬¦å¢åŠ å®¹é”™
                clean_original = original_text.replace(" ", "").replace("\n", "")
                
                if clean_quote in clean_original:
                    valid_records.append(item)
    except json.JSONDecodeError:
        pass
        
    return valid_records

# --- çº¿ç¨‹å·¥ä½œå‡½æ•° ---
def worker(file_path, filename):
    # 1. è¯»å–
    content = read_docx(file_path)
    if not content: return None

    print(f"{Fore.YELLOW}[{filename}] å†·å´ä¸­ (ç­‰å¾…APIé…é¢)...")
    time.sleep(5)
    json_result = analyze_with_gemini(content, filename)
    
    if json_result:
        # 3. æ ¡éªŒ
        valid_data = verify_and_parse(content, json_result)
        return (filename, valid_data)
    return None

# --- ä¸»ç¨‹åº ---
def main():
    conn = init_db()
    cursor = conn.cursor()
    
    # è·å–æ‰€æœ‰ .docx æ–‡ä»¶
    all_files = [f for f in os.listdir(DOC_FOLDER) if f.endswith(".docx")]
    
    # --- ä¿®æ”¹ç‚¹ï¼šåªå–å‰ 10 ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯• ---
    # å¦‚æœæ–‡ä»¶å°‘äº 10 ä¸ªï¼Œå®ƒä¼šè‡ªåŠ¨å–å…¨éƒ¨ï¼Œä¸ä¼šæŠ¥é”™
    files_to_process = all_files[:10] 
    
    print(f"{Fore.GREEN}=== å¯åŠ¨äº‘ç«¯åˆ†æå¼•æ“ (Gemini Flash) ===")
    print(f"æ¨¡å¼: å¿«é€ŸéªŒè¯ (æµ‹è¯•å‰ 10 ç¯‡)") # æç¤ºä¸€ä¸‹å½“å‰æ˜¯æµ‹è¯•æ¨¡å¼
    print(f"ç›®æ ‡æ–‡ä»¶æ•°: {len(files_to_process)} | å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(worker, os.path.join(DOC_FOLDER, f), f): f 
            for f in files_to_process
        }
        
        success_count = 0
        total_points = 0
        
        for future in as_completed(future_to_file):
            filename = future_to_file[future]
            try:
                result = future.result()
                if result:
                    name, points_list = result
                    
                    if points_list:
                        # æ‰¹é‡å…¥åº“
                        for pt in points_list:
                            cursor.execute('''
                                INSERT INTO document_insights 
                                (filename, vendor, topic, stance, key_argument, proposed_parameter, evidence_quote, is_verified)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                            ''', (
                                name, 
                                pt.get('vendor'),
                                pt.get('topic'), # é‡ç‚¹ï¼šç°åœ¨æœ‰äº†å…·ä½“è¯é¢˜
                                pt.get('stance'),
                                pt.get('key_argument'),
                                pt.get('proposed_parameter'),
                                pt.get('evidence_quote'),
                                True
                            ))
                        conn.commit()
                        print(f"{Fore.GREEN}âœ… {name}: æå–åˆ° {len(points_list)} ä¸ªè§‚ç‚¹")
                        success_count += 1
                        total_points += len(points_list)
                    else:
                        print(f"{Fore.YELLOW}âš ï¸ {name}: APIè¿”å›æœ‰æ•ˆä½†æ— é€šè¿‡æ ¡éªŒçš„è§‚ç‚¹")
                else:
                    print(f"{Fore.RED}âŒ {filename}: åˆ†æå¤±è´¥")
            except Exception as e:
                print(f"ç³»ç»Ÿå¼‚å¸¸: {e}")

    conn.close()
    print("="*40)
    print(f"åˆ†æå®Œæˆï¼å…±å¤„ç† {success_count} ä¸ªæ–‡ä»¶ï¼Œå…¥åº“ {total_points} ä¸ªæŠ€æœ¯è§‚ç‚¹ã€‚")
    print(f"æ•°æ®åº“: {DB_NAME}")

if __name__ == "__main__":
    main()
